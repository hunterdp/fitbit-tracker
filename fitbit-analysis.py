# -*- coding: utf-8 -*-
"""Generates analytics for data generated by fitbit-tracker.py

Reads in fitbit data generated by the fitbit-tracker.py program and generates
a series of data insights, graphs, charts and/or tables.

"""
import argparse
import io
import os
import os.path
import sys
import logging
import logging.handlers
import json 

import pandas as pd
import numpy as numpy
import matplotlib.pyplot as plt
import seaborn as sns

from datetime import datetime
from datetime import date
from datetime import timedelta

# Globals
__AUTHOR__ = 'David Hunter'
__VERSION__ = 'fitbit-analysis ver beta-0.1'
__LOG_NAME__ = 'fitbit-analysis.log'
__TITLE__ = 'fitebit-analysis.py'

def set_command_options():
    """Define command line arguments."""

    usage = 'Analyze Fitbit data generated by the fitbit-tracker.py program.'
    parser = argparse.ArgumentParser(prog='Fitbit Analysis', description=usage,
                                     formatter_class=argparse.RawDescriptionHelpFormatter)
    type_group = parser.add_mutually_exclusive_group(required=True)
    date_group = parser.add_mutually_exclusive_group(required=True)

    parser.add_argument('-d', '--debug_level',
                        help='Set the debug level [debug info warn] (default: %(default)s)', action='store', type=str, default='info')
    parser.add_argument('-l', '--log_file', help='Set the logfile name. (default: %(default)s)',
                        action='store', type=str, default='fitbit-tracker.log')
    parser.add_argument('-o', '--output',  help='Output directory to store results files. (default: %(default)s)',
                        action='store', type=str,  dest='output_dir', default='results')
    parser.add_argument('-v', '--version', help='Prints the version',
                        action='version', version=__VERSION__)
    parser.add_argument('-e', '--end_date',  help='End date to collect data from (yyyy-mm-dd)',
                        action='store', type=str,  dest='end_date')

    type_group.add_argument(
        '-a', '--all', help='Analyze all the data possible', action='store_true')
    type_group.add_argument('-t', '--type', help='Analyze only the type of data specified (heartrate, sleep, steps)',
                            action='store', type=str, dest='collect_type')

    date_group.add_argument('-s', '--start_date',  help='Start date to collect data from (yyyy-mm-dd)',
                            action='store', type=str,  dest='start_date')
    date_group.add_argument('--days', help='Number of days to go back and analyze',
                            action='store', type=int, dest='number_of_days')
    date_group.add_argument('--date', help='Specifc date to collect for',
                            action='store', type=str, dest='date_to_collect')
    args = parser.parse_args()
    return(parser)


def get_command_options(parser):
    """ Retrieves the command line options and returns a kv dict """

    args = parser.parse_args()
    fmt = "%(asctime)-15s %(levelname)-8s %(message)s"
    log_file = args.log_file
    options = {'log_file': args.log_file}
    logging.basicConfig(filename=args.log_file, format=fmt, level=logging.INFO)

    if args.all:
        options['analyze_type'] = 'steps heartrate sleep'
    elif args.collect_type:
        options['analyze_type'] = args.collect_type
        logging.info('Analyzing: ' + args.collect_type)
    else:
        logging.error(
            'You need to specify the type of data to analyze or use the -a flag')
        sys.exit(1)

    # TODO(dph): Fix this.  It does not work 
    if args.debug_level:
        if 'debug' in args.debug_level:
            logging.basicConfig(level=logging.DEBUG)
        if 'warn' in args.debug_level:
            logging.basicConfig(level=logging.WARNING)
        elif 'info' in args.debug_level:
            logging.basicConfig(level=logging.INFO)
        elif 'error' in args.debug_level:
            logging.basicConfig(level=logging.ERROR)
        else:
            logging.basicConfig(level=logging.ERROR)
            logging.error('Invalid debug level.  Exiting the program.')
            sys.exit(1)

    if ((args.number_of_days and (args.start_date or args.end_date))
            or (args.date_to_collect and (args.start_date or args.end_date))):
        logging.error('Illegal date specifications.  Exiting')
        sys.exit(1)

    elif args.number_of_days:
        if args.number_of_days <= 0:
            logging.error(
                "Number of days needs to be greater than zero.  Exiting")
            sys.exit(1)
        else:
            options['number_of_days'] = args.number_of_days
            logging.info("Number of days previous: " +
                         str(options['number_of_days']))

    elif args.date_to_collect:
        # Collect for a specific day
        if is_valid_date(args.date_to_collect): 
            options['date_to_collect'] = args.date_to_collect
            logging.info("Date to collect for: " + str(options['date_to_collect']))
        else:
            print('Invalid date specified.  Exiting.')
            logging.error('Invalid date: ' + str(args.date_to_collect))
            sys.exit(1)

    elif args.start_date and args.end_date:
        if not is_valid_date(args.start_date):
            print('Invalid start date specified.  Exiting.')
            logging.error('Invalid start date: ' + str(args.start_date))
            sys.exit(1)
        elif not is_valid_date(args.end_date):
            print('Invalid end date specified.  Exiting.')
            logging.error('Invalid end date: ' + str(args.end_date))
            sys.exit(1)
        else:
            options['start_date'] = args.start_date
            options['end_date'] = args.end_date
            logging.info('Start date: ' + args.start_date)
            logging.info('End date: ' + args.end_date)
            if args.start_date > args.end_date:
                logging.error("Start date is after end date. Exiting.")
                sys.exit(1)

    else:
        # Start and end date not specified.
        logging.error(
            'Both start and end dates need to be specified. Exiting.')
        sys.exit(1)

    if not os.path.isdir(args.output_dir):
        logging.error('Directory does not exist')
        sys.exit(1)
    else:
        options['output_dir'] = args.output_dir

    logging.info(json.dumps(options))
    return(options)

def is_valid_date(date_to_check):
  """ Checks to see if the date is valid """
  year,month,day = date_to_check.split('-',3)
  try :
    date(int(year), int(month), int(day))
  except ValueError :
    return(False)
  return(True)

def get_dataframe(fname):
    """ read in a heartrate file into a dataframe and convert the index into a timedelta value
        and return a dataframe """
    hr_df = pd.read_csv(fname, sep=',', header=0, index_col=0, skip_blank_lines=True, dtype={1: 'Int32'})
    hr_df.index = pd.TimedeltaIndex(hr_df.index)
    return(hr_df)

def get_all_file_list(dir_name, fragment):
    """ Gets a list of files within a directory based on a string in the filename """
    all_files = []
    list_of_files = os.listdir(dir_name)
    for file_name in list_of_files:
        if fragment in file_name:
            full_path_name = os.path.join(dir_name, file_name)
            all_files.append(full_path_name)
    return(all_files)

def date_range(start, end):
  """ Returns a list of dates """
  r = (end+timedelta(days=1)-start).days
  return[start+timedelta(days=i) for i in range(r)]

def get_date_frag(options):
  # Generate a list of file fragments based on dates requested
  if 'end_date' in options and 'start_date' in options:
      start_date = datetime.strptime(options['start_date'], '%Y-%m-%d')
      end_date = datetime.strptime(options['end_date'], '%Y-%m-%d')
      number_of_days_requested = (end_date - start_date).days
      logging.info('Startdate:' + str(start_date))
      logging.info('Enddate:' + str(end_date))
      logging.info('Days requested vale: ' + str(number_of_days_requested))
      logging.info('Number of interger days requested: ' +
                   str(number_of_days_requested))
      date_list = date_range(start_date, end_date)
      logging.debug(date_list)

  elif 'number_of_days' in options:
        # Use the --days option
        today = datetime.today()
        start_date = today - timedelta(days=options['number_of_days'])
        start_date_str = datetime.strftime(start_date, "%Y-%m-%d")
        number_of_days_requested = 1
        logging.info('Collect data for: ' + str(start_date))
        date_list = date_range(start_date,start_date)
        logging.info(date_list)

  elif 'date_to_collect' in options:
        start_date = datetime.strptime(options['date_to_collect'], '%Y-%m-%d')
        start_date_str = options['date_to_collect']
        logging.info('Collect for the specific date:' + start_date_str)
        number_of_days_requested = 1
        date_list = date_range(start_date,start_date)
        logging.debug(date_list)
  else:
        logging.error('No date specified.  Exiting')
        sys.exit(1)

  date_frag_list = list()
  for date in date_list:
      date_frag_list.append(datetime.strftime(date, '%Y-%m-%d'))
  return(date_frag_list) 

##### MAIN PROG STARTS HERE #####
if __name__ == '__main__':
  parser = set_command_options()
  options = get_command_options(parser)
  frag_list = get_date_frag(options)

  # Using the date fragments, generate the list of files to retrieve
  file_list = list()
  for frag in frag_list:
    if 'heartrate' in options['analyze_type']: 
            f1 = options['output_dir'] + '/hr_intraday_' + str(frag) + '.csv'
    elif 'steps' in options['analyze_type']: 
          f1 = options['output_dir'] + '/steps_intraday_' + str(frag) + '.csv'
    else:
          f1 = options['output_dir'] + '/sleep_day_' + str(frag) + '.csv'
    if os.path.exists(f1):
        file_list.append(f1)
  logging.debug(file_list)
  logging.info('The number of elements in file_list is: ' + str(len(file_list)))
  logging.info('The number of elements in frag_list is: ' + str(len(frag_list)))
  # Get data for all the dates....
  #file_list = get_all_file_list('./results', 'hr_intraday_')
  
  # TODO(dph): Make this simplier and not dependent upon the external index file
  # Initalize a dataframe to consolidate the heart rate files.  Generate an index that consists
  # of HH:MM:SS and convert it to the timedelta index.  This is used to ensure that all possible
  # index values in the day can be captured as the FitBit second intervals can vary day to day.
  rng = pd.date_range(start='00:00:00', end='23:59:59', freq='S')
  base_df = pd.DataFrame({'Time': rng.strftime('%H:%M:%S'), 'Day':'0'})
  index_file = options['output_dir'] + '/intraday_index.csv'
  base_df.to_csv(index_file, columns=['Time', 'Index'], header=True, index=False)

  # Create an array of files to merge and for each get a dataframe of the results for the day.
  # TODO(dph): Need to add exception handeling for memory limitations
  merge_df = get_dataframe(index_file)
  for fname in file_list:
    hr_df = get_dataframe(fname)
    merge_df = pd.merge(merge_df, hr_df, left_index=True,right_index=True, how='left')
  logging.debug(merge_df.describe())
  # Drop the initial index column since it is all NaN values
  merge_df = merge_df.drop('Index', axis=1)
  print(merge_df.describe())

  # Start analysing the dataframe
  # Generate some basic information about the dataframe
  print(merge_df.shape)
  print('\n')
  print(merge_df.head(3))
  print(merge_df.tail(3))
  print(merge_df.dtypes)
  
  sys.exit(0)
  # Draw a simple chart of the number of elements per day
  #sns.set(rc={'figure.figsize':(11,4)})
  plt.style.use('classic')
   
  h = merge_df.hist(figsize = (15,20), layout = (6,3), xrot = 30)
  #h = merge_df.hist()
  
  # Finally show the plots/charts.  Only call this at the end.
  plt.show()